{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "colab": {
      "name": "Digit-Recognizer-MNIST.ipynb",
      "provenance": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BRu2Rkzp6BbS",
        "colab_type": "text"
      },
      "source": [
        "# [Kaggle] Digit Recognizer \n",
        "\n",
        "MNIST (\"Modified National Institute of Standards and Technology\") is the de facto “hello world” dataset of computer vision. Since its release in 1999, this classic dataset of handwritten images has served as the basis for benchmarking classification algorithms. As new machine learning techniques emerge, MNIST remains a reliable resource for researchers and learners alike.\n",
        "\n",
        "In this competition, our goal is to correctly identify digits from a dataset of tens of thousands of handwritten images.\n",
        "\n",
        "> https://www.kaggle.com/c/digit-recognizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rIGF9uL86BbU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from tensorflow.keras.layers import Input, Conv2D, MaxPooling2D, Dense, Flatten, Dropout, Activation, BatchNormalization\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras.regularizers import l2\n",
        "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import math"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b-6lKxc-6BbX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ef611b9c-4e2c-45b4-aef2-53080fcd5267"
      },
      "source": [
        "print(tf.__version__)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.2.0-rc3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cva2pBRm6Bbb",
        "colab_type": "text"
      },
      "source": [
        "## Model\n",
        "\n",
        "### Implemented a modified LeNet-5. \n",
        "\n",
        "**LeNet-5** - GradientBased Learning Applied to Document Recognition (Yann LeCun Leon Bottou Yoshua Bengio and Patrick Haffner) (http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf)\n",
        "\n",
        "### [LeNet-5] Original Architecture\n",
        "\n",
        "ConvNet --> Pool --> ConvNet --> Pool --> (Flatten) --> FullyConnected --> FullyConnected --> Softmax \n",
        "\n",
        "### Results\n",
        "\n",
        "**epochs** - 30  \n",
        "**loss** - 0.0016  \n",
        "**train_accuracy** -  0.9998  \n",
        "**val_loss** -  0.0412  \n",
        "**val_accuracy** - 0.9905  \n",
        "\n",
        "#### Highest Dev Set Accuracy Obtained - 99.05%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zzwT2Buy6Bbc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNet5(input_shape = (32, 32, 1), classes = 10):\n",
        "    \"\"\"\n",
        "    Implementation of a modified LeNet-5.\n",
        "    Modified Architecture -- ConvNet --> Pool --> ConvNet --> Pool --> (Flatten) --> FullyConnected --> FullyConnected --> Softmax \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        \n",
        "    # Layer 1\n",
        "    Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,1), name = 'convolution_1'),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n",
        "        \n",
        "    # Layer 2\n",
        "    Conv2D(filters = 16, kernel_size = 5, strides = 1, activation = 'relu', name = 'convolution_2'),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n",
        "        \n",
        "    # Layer 3\n",
        "    Flatten(name = 'flatten'),\n",
        "    Dense(units = 120, activation = 'relu', name = 'fully_connected_1'),\n",
        "        \n",
        "    # Layer 4\n",
        "    Dense(units = 84, activation = 'relu', name = 'fully_connected_2'),\n",
        "    \n",
        "    # Output\n",
        "    Dense(units = 10, activation = 'softmax', name = 'output')\n",
        "        \n",
        "    ])\n",
        "    \n",
        "    model._name = 'LeNet5'\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LlJQLCOX6Bbe",
        "colab_type": "text"
      },
      "source": [
        "### [LeNet-5] Modified Architecture\n",
        "\n",
        "ConvNet --> **ConvNet** --> Pool --> **(Dropout)** --> ConvNet --> Pool --> **(Dropout)** --> (Flatten) --> FullyConnected --> FullyConnected --> Softmax \n",
        "\n",
        "### Results\n",
        "\n",
        "**epochs** - 30  \n",
        "**loss** - 0.0319  \n",
        "**train_accuracy** -  0.9918  \n",
        "**val_loss** -  0.0327  \n",
        "**val_accuracy** - 0.9929  \n",
        "\n",
        "#### Highest Dev Set Accuracy Obtained - 99.29%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O38-h8R86Bbf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNet5v1(input_shape = (32, 32, 1), classes = 10):\n",
        "    \"\"\"\n",
        "    Implementation of a modified LeNet-5.\n",
        "    Modified Architecture -- ConvNet --> ConvNet --> Pool --> (Dropout) --> ConvNet --> Pool --> (Dropout) --> (Flatten) --> FullyConnected --> FullyConnected --> Softmax \n",
        "\n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        \n",
        "    # Layer 1\n",
        "    Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,1), name = 'convolution_1'),\n",
        "    \n",
        "    # Layer 2    \n",
        "    Conv2D(filters = 6, kernel_size = 5, strides = 1, activation = 'relu', name = 'convolution_2'),\n",
        "    \n",
        "    # -------------------------------- # \n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n",
        "    Dropout(0.25, name = 'dropout_1'),\n",
        "    # -------------------------------- # \n",
        "        \n",
        "    # Layer 3\n",
        "    Conv2D(filters = 16, kernel_size = 5, strides = 1, activation = 'relu', kernel_regularizer = l2(0.01), name = 'convolution_3'),\n",
        "    \n",
        "    # -------------------------------- # \n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n",
        "    Dropout(0.25, name = 'dropout_2'),\n",
        "    Flatten(name = 'flatten'),\n",
        "    # -------------------------------- # \n",
        "        \n",
        "    # Layer 4\n",
        "    Dense(units = 120, activation = 'relu', name = 'fully_connected_1'),\n",
        "        \n",
        "    # Layer 5\n",
        "    Dense(units = 84, activation = 'relu', name = 'fully_connected_2'),\n",
        "    \n",
        "    # Output\n",
        "    Dense(units = 10, activation = 'softmax', name = 'output')\n",
        "        \n",
        "    ])\n",
        "    \n",
        "    model._name = 'LeNet5v1'\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VmJKdBrC6Bbi",
        "colab_type": "text"
      },
      "source": [
        "### [LeNet-5] Modified Architecture\n",
        "\n",
        "ConvNet --> **ConvNet** --> **BatchNorm** --> Pool --> **(Dropout)** --> ConvNet --> **ConvNet** --> **BatchNorm** --> Pool --> **(Dropout)** --> (Flatten) --> **FullyConnected** --> **BatchNorm** --> FullyConnected --> **BatchNorm** --> FullyConnected --> **BatchNorm** --> Softmax \n",
        "\n",
        "### Results\n",
        "\n",
        "**epochs** - 30  \n",
        "**loss** - 0.0113  \n",
        "**train_accuracy** - 0.9966   \n",
        "**val_loss** -  0.0176  \n",
        "**val_accuracy** - 0.9957  \n",
        "\n",
        "#### Highest Dev Set Accuracy Obtained - 99.57%"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vP3BMEMy6Bbi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def LeNet5v2(input_shape = (32, 32, 1), classes = 10):\n",
        "    \"\"\"\n",
        "    Implementation of a modified LeNet-5.\n",
        "    Only those layers with learnable parameters are counted in the layer numbering.\n",
        "    \n",
        "    Arguments:\n",
        "    input_shape -- shape of the images of the dataset\n",
        "    classes -- integer, number of classes\n",
        "\n",
        "    Returns:\n",
        "    model -- a Model() instance in Keras\n",
        "    \"\"\"\n",
        "    \n",
        "    model = Sequential([\n",
        "        \n",
        "    # Layer 1\n",
        "    Conv2D(filters = 32, kernel_size = 5, strides = 1, activation = 'relu', input_shape = (32,32,1), name = 'convolution_1'),\n",
        "    \n",
        "    # Layer 2\n",
        "    Conv2D(filters = 32, kernel_size = 5, strides = 1, name = 'convolution_2', use_bias=False),\n",
        "    \n",
        "    # Layer 3    \n",
        "    BatchNormalization(name = 'batchnorm_1'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_1'),\n",
        "    Dropout(0.25, name = 'dropout_1'),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 3\n",
        "    Conv2D(filters = 64, kernel_size = 3, strides = 1, activation = 'relu', name = 'convolution_3'),\n",
        "        \n",
        "    # Layer 4\n",
        "    Conv2D(filters = 64, kernel_size = 3, strides = 1, name = 'convolution_4', use_bias=False),\n",
        "        \n",
        "    # Layer 5\n",
        "    BatchNormalization(name = 'batchnorm_2'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    MaxPooling2D(pool_size = 2, strides = 2, name = 'max_pool_2'),\n",
        "    Dropout(0.25, name = 'dropout_2'),\n",
        "    Flatten(name = 'flatten'),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 6\n",
        "    Dense(units = 256, name = 'fully_connected_1', use_bias=False),\n",
        "        \n",
        "    # Layer 7\n",
        "    BatchNormalization(name = 'batchnorm_3'),\n",
        "    \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 8\n",
        "    Dense(units = 128, name = 'fully_connected_2', use_bias=False),\n",
        "        \n",
        "    # Layer 9\n",
        "    BatchNormalization(name = 'batchnorm_4'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    # -------------------------------- #  \n",
        "        \n",
        "    # Layer 10\n",
        "    Dense(units = 84, name = 'fully_connected_3', use_bias=False),\n",
        "        \n",
        "    # Layer 11\n",
        "    BatchNormalization(name = 'batchnorm_5'),\n",
        "        \n",
        "    # -------------------------------- #  \n",
        "    Activation(\"relu\"),\n",
        "    Dropout(0.25, name = 'dropout_3'),\n",
        "    # -------------------------------- #  \n",
        "\n",
        "    # Output\n",
        "    Dense(units = 10, activation = 'softmax', name = 'output')\n",
        "        \n",
        "    ])\n",
        "    \n",
        "    model._name = 'LeNet5v2'\n",
        "\n",
        "    return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KPVOreYI6Bbl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LeNet5Model = LeNet5v2(input_shape = (32, 32, 1), classes = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_WE7wIWR6Bbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "LeNet5Model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bKRpyBC56Bbq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 969
        },
        "outputId": "5d961e9e-3c1e-403b-9fd2-5137c59570a2"
      },
      "source": [
        "LeNet5Model.summary()"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"LeNet5v2\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "convolution_1 (Conv2D)       (None, 28, 28, 32)        832       \n",
            "_________________________________________________________________\n",
            "convolution_2 (Conv2D)       (None, 24, 24, 32)        25600     \n",
            "_________________________________________________________________\n",
            "batchnorm_1 (BatchNormalizat (None, 24, 24, 32)        128       \n",
            "_________________________________________________________________\n",
            "activation_10 (Activation)   (None, 24, 24, 32)        0         \n",
            "_________________________________________________________________\n",
            "max_pool_1 (MaxPooling2D)    (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 12, 12, 32)        0         \n",
            "_________________________________________________________________\n",
            "convolution_3 (Conv2D)       (None, 10, 10, 64)        18496     \n",
            "_________________________________________________________________\n",
            "convolution_4 (Conv2D)       (None, 8, 8, 64)          36864     \n",
            "_________________________________________________________________\n",
            "batchnorm_2 (BatchNormalizat (None, 8, 8, 64)          256       \n",
            "_________________________________________________________________\n",
            "activation_11 (Activation)   (None, 8, 8, 64)          0         \n",
            "_________________________________________________________________\n",
            "max_pool_2 (MaxPooling2D)    (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4, 4, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 1024)              0         \n",
            "_________________________________________________________________\n",
            "fully_connected_1 (Dense)    (None, 256)               262144    \n",
            "_________________________________________________________________\n",
            "batchnorm_3 (BatchNormalizat (None, 256)               1024      \n",
            "_________________________________________________________________\n",
            "activation_12 (Activation)   (None, 256)               0         \n",
            "_________________________________________________________________\n",
            "fully_connected_2 (Dense)    (None, 128)               32768     \n",
            "_________________________________________________________________\n",
            "batchnorm_4 (BatchNormalizat (None, 128)               512       \n",
            "_________________________________________________________________\n",
            "activation_13 (Activation)   (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "fully_connected_3 (Dense)    (None, 84)                10752     \n",
            "_________________________________________________________________\n",
            "batchnorm_5 (BatchNormalizat (None, 84)                336       \n",
            "_________________________________________________________________\n",
            "activation_14 (Activation)   (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "dropout_3 (Dropout)          (None, 84)                0         \n",
            "_________________________________________________________________\n",
            "output (Dense)               (None, 10)                850       \n",
            "=================================================================\n",
            "Total params: 390,562\n",
            "Trainable params: 389,434\n",
            "Non-trainable params: 1,128\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1rH9irWw6Bbs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9Jw_5Yy6Bbu",
        "colab_type": "text"
      },
      "source": [
        "## Kaggle Data Processing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NvBD5ecM6Bbv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 316
        },
        "outputId": "329a7322-9b2a-4a7d-9d28-a50b569cffa1"
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')\n",
        "\n",
        "Y = train[['label']]\n",
        "X = train.drop(train.columns[[0]], axis=1)\n",
        "\n",
        "X = X.values.reshape(-1,28,28,1)\n",
        "test = test.values.reshape(-1,28,28,1)\n",
        "\n",
        "print(\"Size of Dataset: \" , len(X))\n",
        "\n",
        "cross_validation_size = int(len(X)*0.05)\n",
        "\n",
        "print(\"Size of Cross Validation Set: \" , cross_validation_size)\n",
        "\n",
        "random_seed = 2\n",
        "X_train, X_val, Y_train, Y_val = train_test_split(X, Y, test_size = cross_validation_size, random_state=random_seed)\n",
        "\n",
        "X_test = test\n",
        "\n",
        "plt.imshow(X_train[0][:,:,0])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Size of Dataset:  42000\n",
            "Size of Cross Validation Set:  2100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7fca1604dc50>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "05nGMrbm6Bbx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train = np.array(X_train)\n",
        "X_val = np.array(X_val)\n",
        "X_test = np.array(X_test)\n",
        "\n",
        "# Padding the images by 2 pixels since in the paper input images were 32x32\n",
        "X_train = np.pad(X_train, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "X_val = np.pad(X_val, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "X_test = np.pad(X_test, ((0,0),(2,2),(2,2),(0,0)), 'constant')\n",
        "\n",
        "# Standardization\n",
        "mean_px = X_train.mean().astype(np.float32)\n",
        "std_px = X_train.std().astype(np.float32)\n",
        "X_train = (X_train - mean_px)/(std_px)\n",
        "\n",
        "mean_px = X_val.mean().astype(np.float32)\n",
        "std_px = X_val.std().astype(np.float32)\n",
        "X_val = (X_val - mean_px)/(std_px)\n",
        "\n",
        "mean_px = X_test.mean().astype(np.float32)\n",
        "std_px = X_test.std().astype(np.float32)\n",
        "X_test = (X_test - mean_px)/(std_px)\n",
        "\n",
        "# One-hot encoding the labels\n",
        "Y_train = to_categorical(Y_train, num_classes = 10)\n",
        "Y_val = to_categorical(Y_val, num_classes = 10)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C-EpjOba6Bb0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# By using the image generator, we are not generating new data. We are only replacing the exisiting images. \n",
        "\n",
        "datagen = ImageDataGenerator(\n",
        "        featurewise_center = False,  # set input mean to 0 over the dataset\n",
        "        samplewise_center = False,  # set each sample mean to 0\n",
        "        featurewise_std_normalization = False,  # divide inputs by std of the dataset\n",
        "        samplewise_std_normalization = False,  # divide each input by its std\n",
        "        zca_whitening = False,  # apply ZCA whitening\n",
        "        rotation_range = 10,  # randomly rotate images in the range (degrees, 0 to 180)\n",
        "        zoom_range = 0.1, # Randomly zoom image \n",
        "        width_shift_range = 0.1,  # randomly shift images horizontally (fraction of total width)\n",
        "        height_shift_range = 0.1,  # randomly shift images vertically (fraction of total height)\n",
        "        horizontal_flip = False,  # randomly flip images\n",
        "        vertical_flip = False)  # randomly flip images\n",
        "\n",
        "datagen.fit(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h1K3pH4W6Bb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti9fic6R6Bb4",
        "colab_type": "text"
      },
      "source": [
        "### Variable Learning Rate "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QzelRWLT6Bb5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "variable_learning_rate = ReduceLROnPlateau(monitor='val_loss', factor = 0.2, patience = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NmnLaU1h6Bb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DBY7Qi_G6Bb9",
        "colab_type": "text"
      },
      "source": [
        "### Model Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "8aFRDFKK6Bb9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "8ff420c0-8ff5-4198-a69f-8920f6a3460d"
      },
      "source": [
        "history = LeNet5Model.fit(X_train, Y_train, epochs = 30, batch_size = 64, callbacks = [variable_learning_rate], validation_data = (X_val,Y_val))"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0061 - accuracy: 0.9984 - val_loss: 0.0146 - val_accuracy: 0.9952 - lr: 1.3422e-22\n",
            "Epoch 2/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0145 - val_accuracy: 0.9948 - lr: 1.3422e-22\n",
            "Epoch 3/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0070 - accuracy: 0.9980 - val_loss: 0.0144 - val_accuracy: 0.9952 - lr: 1.3422e-22\n",
            "Epoch 4/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0070 - accuracy: 0.9978 - val_loss: 0.0146 - val_accuracy: 0.9948 - lr: 1.3422e-22\n",
            "Epoch 5/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0072 - accuracy: 0.9980 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 1.3422e-22\n",
            "Epoch 6/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0066 - accuracy: 0.9980 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 2.6844e-23\n",
            "Epoch 7/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0069 - accuracy: 0.9982 - val_loss: 0.0145 - val_accuracy: 0.9952 - lr: 2.6844e-23\n",
            "Epoch 8/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0068 - accuracy: 0.9982 - val_loss: 0.0146 - val_accuracy: 0.9952 - lr: 5.3687e-24\n",
            "Epoch 9/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0073 - accuracy: 0.9978 - val_loss: 0.0143 - val_accuracy: 0.9957 - lr: 5.3687e-24\n",
            "Epoch 10/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0067 - accuracy: 0.9983 - val_loss: 0.0145 - val_accuracy: 0.9948 - lr: 1.0737e-24\n",
            "Epoch 11/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0074 - accuracy: 0.9977 - val_loss: 0.0143 - val_accuracy: 0.9948 - lr: 1.0737e-24\n",
            "Epoch 12/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0077 - accuracy: 0.9976 - val_loss: 0.0144 - val_accuracy: 0.9952 - lr: 2.1475e-25\n",
            "Epoch 13/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0072 - accuracy: 0.9978 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 2.1475e-25\n",
            "Epoch 14/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 4.2950e-26\n",
            "Epoch 15/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0071 - accuracy: 0.9979 - val_loss: 0.0146 - val_accuracy: 0.9952 - lr: 4.2950e-26\n",
            "Epoch 16/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0077 - accuracy: 0.9978 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 8.5899e-27\n",
            "Epoch 17/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0074 - accuracy: 0.9979 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 8.5899e-27\n",
            "Epoch 18/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0070 - accuracy: 0.9981 - val_loss: 0.0142 - val_accuracy: 0.9957 - lr: 1.7180e-27\n",
            "Epoch 19/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0069 - accuracy: 0.9978 - val_loss: 0.0143 - val_accuracy: 0.9957 - lr: 1.7180e-27\n",
            "Epoch 20/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0069 - accuracy: 0.9981 - val_loss: 0.0145 - val_accuracy: 0.9948 - lr: 1.7180e-27\n",
            "Epoch 21/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0066 - accuracy: 0.9978 - val_loss: 0.0144 - val_accuracy: 0.9952 - lr: 3.4360e-28\n",
            "Epoch 22/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0072 - accuracy: 0.9979 - val_loss: 0.0144 - val_accuracy: 0.9952 - lr: 3.4360e-28\n",
            "Epoch 23/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0067 - accuracy: 0.9980 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 6.8719e-29\n",
            "Epoch 24/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0073 - accuracy: 0.9976 - val_loss: 0.0146 - val_accuracy: 0.9948 - lr: 6.8719e-29\n",
            "Epoch 25/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0069 - accuracy: 0.9977 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 1.3744e-29\n",
            "Epoch 26/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0073 - accuracy: 0.9980 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 1.3744e-29\n",
            "Epoch 27/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0072 - accuracy: 0.9977 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 2.7488e-30\n",
            "Epoch 28/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0070 - accuracy: 0.9979 - val_loss: 0.0144 - val_accuracy: 0.9948 - lr: 2.7488e-30\n",
            "Epoch 29/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0068 - accuracy: 0.9981 - val_loss: 0.0143 - val_accuracy: 0.9952 - lr: 5.4976e-31\n",
            "Epoch 30/30\n",
            "624/624 [==============================] - 5s 8ms/step - loss: 0.0076 - accuracy: 0.9978 - val_loss: 0.0145 - val_accuracy: 0.9948 - lr: 5.4976e-31\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ku4GlfnI6BcA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 563
        },
        "outputId": "008f7919-c596-46de-b593-672235803837"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.image  as mpimg\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "#-----------------------------------------------------------\n",
        "# Retrieve a list of list results on training and test data\n",
        "# sets for each training epoch\n",
        "#-----------------------------------------------------------\n",
        "acc=history.history['accuracy']\n",
        "val_acc=history.history['val_accuracy']\n",
        "loss=history.history['loss']\n",
        "val_loss=history.history['val_loss']\n",
        "\n",
        "epochs=range(len(acc)) # Get number of epochs\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation accuracy per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, acc, 'r', \"Training Accuracy\")\n",
        "plt.plot(epochs, val_acc, 'b', \"Validation Accuracy\")\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.figure()\n",
        "\n",
        "#------------------------------------------------\n",
        "# Plot training and validation loss per epoch\n",
        "#------------------------------------------------\n",
        "plt.plot(epochs, loss, 'r', \"Training Loss\")\n",
        "plt.plot(epochs, val_loss, 'b', \"Validation Loss\")\n",
        "plt.figure()"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7vC-6K1e6BcB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xir0WKsj6BcD",
        "colab_type": "text"
      },
      "source": [
        "### Submission"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GlAE5LSp6BcE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "results = LeNet5Model.predict(X_test)\n",
        "results = np.argmax(results,axis = 1)\n",
        "results = pd.Series(results,name=\"Label\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-w33Crgt6BcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n",
        "submission.to_csv(\"LeNetv2.csv\",index=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mA-Gf-JZ6BcK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibAgbyo16BcM",
        "colab_type": "text"
      },
      "source": [
        "### References\n",
        "\n",
        "* **Yassine Ghouzam**, PhD - Parameters for Data Augmentation using Image Data Generator, Variable Learning Rate using ReduceLROnPlateau (https://www.kaggle.com/yassineghouzam/introduction-to-cnn-keras-0-997-top-6)\n",
        "\n",
        "* **Taavish Thaman** - LeNet-5 Keras (https://github.com/TaavishThaman/LeNet-5-with-Keras)"
      ]
    }
  ]
}